import torch
from diffusers import ZImagePipeline
import os

# 1. ëª¨ë¸ ì¤€ë¹„ (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
pipe = ZImagePipeline.from_pretrained(
    "Tongyi-MAI/Z-Image-Turbo", 
    torch_dtype=torch.bfloat16, 
    use_safetensors=True, 
    # trust_remote_code=True
)
pipe.to("cuda")
# pipe.vae.to(dtype=torch.float32)

# 2. í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •
prompt = "A high-tech mechanical keyboard with RGB lighting, macro photography, detailed keycaps"
steps_to_test = [1, 4, 8, 16]      # ë§ì¹˜ì§ˆ íšŸìˆ˜ í…ŒìŠ¤íŠ¸
guidance_to_test = [0.0, 1.5, 5.0] # ì”ì†Œë¦¬ ê°•ë„ í…ŒìŠ¤íŠ¸

os.makedirs("sweep_results", exist_ok=True)

# 3. ì¤‘ì²© ë£¨í”„ë¡œ ëª¨ë“  ì¡°í•© í…ŒìŠ¤íŠ¸ (Grid Search)
print("ğŸš€ ë§¤íŠ¸ë¦­ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
for steps in steps_to_test:
    for gs in guidance_to_test:
        filename = f"sweep_results/step{steps}_gs{gs}.png"
        print(f"ğŸ¬ ìƒì„± ì¤‘: Steps {steps}, Guidance {gs} -> {filename}")
        
        # ì‹œë“œ ê³ ì • (ë³€ìˆ˜ ì°¨ì´ë¥¼ ëª…í™•íˆ ë³´ê¸° ìœ„í•´ ë™ì¼í•œ ì´ˆê¸° ë…¸ì´ì¦ˆ ì‚¬ìš©)
        generator = torch.Generator("cuda").manual_seed(42)
        
        image = pipe(
            prompt=prompt,
            num_inference_steps=steps,
            guidance_scale=gs,
            generator=generator
        ).images[0]
        
        image.save(filename)

print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ! 'sweep_results' í´ë”ì˜ íŒŒì¼ë“¤ì„ ë¹„êµí•´ ë³´ì„¸ìš”.")